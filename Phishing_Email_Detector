# -*- coding: utf-8 -*-
"""Phishing Email Detector

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1quCOvG6tGGXsWdJBQAxsamJ0qiSHpt5P

# 2.1 DATASET COLLECTION

**Add files and download appropiate libraries:**
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('emails.csv')
print(df.head())

"""# 2.2 DATA PRE-PROCESSING

**Clean the "Message" section of dataset:**
"""

import pandas as pd
import re
import nltk
nltk.download('punkt')
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv('emails.csv')

# Basic cleaning function
def clean_text(text):
    text = str(text)
    text = BeautifulSoup(text, "html.parser").get_text()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = text.lower()
    return text

df['Cleaned_Message'] = df['text'].apply(clean_text)

"""**Vectorize, find TF-IDF, and tokenize the cleaned text:**"""

vectorizer = TfidfVectorizer(stop_words='english', token_pattern=r'\b[a-zA-Z]{3,}\b')
#\b[a-zA-Z]{2,}\b filters out numbers and words shorter than 2 characters.

X_tfidf = vectorizer.fit_transform(df['Cleaned_Message'])

feature_names = vectorizer.get_feature_names_out()
print("Top 10 words:", feature_names[:10])

"""# 2.3 MODELING

**Import different machine learning models and apply to table:**
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import pandas as pd

# 1. Split data
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['spam'], test_size=0.2, random_state=42)

# 2. Define models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Multinomial Naive Bayes': MultinomialNB(),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM (RBF)': SVC(kernel='rbf', C=10, gamma=0.1, probability=True),
}

"""# 2.4 MODEL EVALUATION

**Use Grid Search to find optimal settings for SVC**
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.1, 1, 10],
    'gamma': ['scale', 0.01, 0.1, 1],
    'kernel': ['rbf']
}

grid = GridSearchCV(SVC(probability=True), param_grid, cv=5)
grid.fit(X_train, y_train)

print("Best params:", grid.best_params_)

"""**K-Fold Cross selection:**"""

from sklearn.model_selection import cross_val_score

for name, model in models.items():
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    print(f"{name} - Mean Accuracy: {scores.mean():.4f}")

"""**Compare each model by creating a confusion matrix and a classification report:**"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report
#### For confusion matrix
import matplotlib.pyplot as plt
import seaborn as sns
####

results= []
classification_reports = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)

    roc_auc = roc_auc_score(y_test, y_proba[:, 1], multi_class='ovr')

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for {name}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    results.append({
        'Model': name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, average="weighted", zero_division=0),
        'Recall': recall_score(y_test, y_pred, average="weighted", zero_division=0),
        'F1 Score': f1_score(y_test, y_pred, average="weighted", zero_division=0),
        'ROC-AUC': roc_auc
    })

    classification_reports[name] = classification_report(y_test, y_pred, zero_division=0)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))  # Bigger plot

for name, model in models.items():
    y_proba = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5)
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()  # Shrinks margins
plt.show()

"""## Summary of Model Performance

Here's a table summarizing the performance of each model based on various evaluation metrics:
"""

print("Detailed Classification Reports:")
for name, report in classification_reports.items():
    print(f"\n{name}:\n{report}")

"""Knowing SVM is the best model, we export and save the tf-idf and"""

from sklearn.svm import SVC

svm_model = SVC(kernel='linear', C=10, gamma=0.1, probability=True)
svm_model.fit(X_train, y_train)

import pickle

# Save the trained SVM model
with open("model.pkl", "wb") as f:
    pickle.dump(svm_model, f)

# Save the vectorizer
with open("tfidf.pkl", "wb") as f:
    pickle.dump(vectorizer, f)

from google.colab import files

files.download("model.pkl")
files.download("tfidf.pkl")

"""# BERT (Deep Learning Implementation"""

!pip install transformers datasets
!pip install -U transformers

import pandas as pd

# Load
df = pd.read_csv('emails.csv')
df = df[['text', 'spam']]
df.columns = ['text', 'label']
df['label'] = df['label'].astype(int)
df.head()

from transformers import BertTokenizer
from datasets import Dataset

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

hf_dataset = Dataset.from_pandas(df)

def tokenize_function(example):
    return tokenizer(example['text'], padding="max_length", truncation=True, max_length=512)

tokenized_dataset = hf_dataset.map(tokenize_function, batched=True)

split_dataset = tokenized_dataset.train_test_split(test_size=0.2)
train_ds = split_dataset['train']
test_ds = split_dataset['test']

from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2,device_map="cpu")

from transformers import TrainingArguments, Trainer
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Define evaluation metrics
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')
    acc = accuracy_score(labels, predictions)
    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}

# Training configuration
training_args = TrainingArguments(
    output_dir="./bert-spam-output",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    logging_dir="./logs",
    save_strategy="no",
    fp16=True
)

# Create Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=test_ds,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

trainer.evaluate()

model.save_pretrained("bert_model/")
tokenizer.save_pretrained("bert_model/")
